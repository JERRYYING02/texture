{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JERRYYING02/texture/blob/main/Copy_of_texture_tiling_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Documentation\n",
        "\n",
        "1. You need to run everything before the \"Choose your algorithm\" section. The exception is the \"Connect Google Drive\". It is for downloading sample images, you won't need them if you are going to use your own.\n",
        "2. You can pick the algorithm you need and run it solely.\n",
        "Each of the blocks contains a line of form:\n",
        "```python\n",
        "source_image = PIL.Image.open(\"Cables.png\").convert(\"RGB\")\n",
        "```\n",
        "This is where your image is loaded. You should upload your image into Google Colab, and change filename here.\n",
        "To upload an image just drag and drop it in the *files* section on the left.\n",
        "3. After execution an image will appear in the notebook. If you right-click it a dropdown menu should appear. You can download the image from there."
      ],
      "metadata": {
        "id": "v0UIKkOdYFTm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports and Configurations"
      ],
      "metadata": {
        "id": "dmvfhjDOprXE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv36dznyWPr6"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "import PIL.ImageOps\n",
        "import PIL.ImageDraw as dw\n",
        "import torch\n",
        "import torchvision.models.vgg as vgg\n",
        "from torch.nn.functional import interpolate, mse_loss, avg_pool2d, grid_sample, pad\n",
        "from torch import nn\n",
        "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
        "import math\n",
        "import cmath\n",
        "from ipywidgets import interact\n",
        "import tqdm.notebook as tqdm\n",
        "import itertools\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu5-w7bwWTwx"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\"\n",
        "\n",
        "style_layers = [1, 6, 12, 18]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mIa61KSrs7J"
      },
      "source": [
        "## Connect Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c26U2ULr0kw"
      },
      "outputs": [],
      "source": [
        "# libraries for the files in google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "# from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emGwd6Bsr16y"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "files = {\n",
        "    # \"Kandinsky.jpg\": '1Igk0jfnHukONLNYfLHnbjKzEoZspHf4-',\n",
        "    \"Cables.png\": '1xhnMp8Cb2AMtmjbo6bKX1_SQqFGwG2Ah'\n",
        "}\n",
        "\n",
        "for filename, fileid in files.items():\n",
        "    download = drive.CreateFile({'id': fileid})\n",
        "    download.GetContentFile(filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W5GIO3LeIVIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_image = PIL.Image.open('/content/drive/My Drive/wood.webp').convert(\"RGB\")"
      ],
      "metadata": {
        "id": "L5_Q33erIx4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_image"
      ],
      "metadata": {
        "id": "al8ReI66I22G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1uPiF-kX8r6"
      },
      "source": [
        "# Commons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b2oQ4oyWYHu"
      },
      "outputs": [],
      "source": [
        "feature_extractor = vgg.vgg16(vgg.VGG16_Weights.IMAGENET1K_FEATURES).features.to(device)\n",
        "\n",
        "for layer in feature_extractor:\n",
        "    if hasattr(layer, \"padding\"):\n",
        "        layer.padding = (0, 0)\n",
        "\n",
        "def extract_features(input_tensor, mode=\"circular\"):\n",
        "    result = []\n",
        "    for i, layer in enumerate(feature_extractor):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            input_tensor = pad(input_tensor, (1, 1, 1, 1), mode=mode)\n",
        "        input_tensor = layer(input_tensor)\n",
        "        if i in style_layers:\n",
        "            result.append(input_tensor)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StDVP9kjWbEY"
      },
      "outputs": [],
      "source": [
        "def gram(x):\n",
        "    n, c, h, w = x.shape\n",
        "    return torch.einsum(\"nchw,nkhw->nck\", x, x) / (h * w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Po2qEtWbSB"
      },
      "outputs": [],
      "source": [
        "def run_optimization(latent_tensor,\n",
        "                     source_tensor,\n",
        "                     uvmap,\n",
        "                     number_of_iterations=80,\n",
        "                     mode=\"circular\"):\n",
        "    optimizer = torch.optim.LBFGS([latent_tensor], history_size=5)\n",
        "    with torch.no_grad():\n",
        "        source_grams = [gram(t) for t in extract_features(source_tensor,\n",
        "                                                          mode=\"reflect\")]\n",
        "    def closure():\n",
        "        with torch.no_grad():\n",
        "            latent_tensor.clamp_(0, 1)\n",
        "            resolution = latent_tensor.shape[-1]\n",
        "        generated_tensor = grid_sample(\n",
        "            latent_tensor,\n",
        "            uvmap[None],\n",
        "            \"nearest\",\n",
        "            \"border\",\n",
        "            True,\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        generated_grams = [gram(t) for t in extract_features(generated_tensor,\n",
        "                                                             mode=mode)]\n",
        "        loss_gram = sum(mse_loss(g, s) for g, s in zip(generated_grams,\n",
        "                                                       source_grams))\n",
        "        loss_tv = torch.abs(latent_tensor[:, :, 1:-1, 1:-1] -\n",
        "                            avg_pool2d(latent_tensor,\n",
        "                                       (3, 3),\n",
        "                                       (1, 1))\n",
        "                            ).mean()\n",
        "        loss = loss_gram + loss_tv\n",
        "        loss_gram.backward()\n",
        "        return loss\n",
        "\n",
        "    progress_bar = tqdm.trange(number_of_iterations)\n",
        "    for stage in progress_bar:\n",
        "        loss = optimizer.step(closure)\n",
        "        progress_bar.set_description(f\"loss = {loss.item():.3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGvddKhWXwKu"
      },
      "source": [
        "## Different Tiling Methods"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_uvmap_identity(resolution):\n",
        "    x, y = torch.meshgrid(torch.linspace(-1, 1, resolution),\n",
        "                          torch.linspace(-1, 1, resolution))\n",
        "\n",
        "    xy = torch.stack([y, x], dim=0)\n",
        "    return torch.movedim(xy, 0, -1).to(device)\n"
      ],
      "metadata": {
        "id": "71-Z7AVA_0Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBuMbmocYKD_"
      },
      "outputs": [],
      "source": [
        "def create_uvmap_square_tiling(resolution, canvas_multiplier=2):\n",
        "    x, y = torch.meshgrid(torch.linspace(-canvas_multiplier,\n",
        "                                         canvas_multiplier,\n",
        "                                         canvas_multiplier * resolution),\n",
        "                          torch.linspace(-canvas_multiplier,\n",
        "                                         canvas_multiplier,\n",
        "                                         canvas_multiplier * resolution))\n",
        "\n",
        "    xy = torch.stack([y, x], dim=0)\n",
        "    xy = (xy + 1.0 + 2 * canvas_multiplier) % 2.0 - 1.0\n",
        "    return torch.movedim(xy, 0, -1).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_uvmap_edge_tiling(resolution, canvas_multiplier=2):\n",
        "    x, y = torch.meshgrid(torch.linspace(-canvas_multiplier,\n",
        "                                         canvas_multiplier,\n",
        "                                         int(canvas_multiplier * resolution)),\n",
        "                          torch.linspace(-canvas_multiplier,\n",
        "                                         canvas_multiplier,\n",
        "                                         int(canvas_multiplier * resolution)))\n",
        "\n",
        "    xy = torch.stack([y, x], dim=0)\n",
        "    xy = torch.clamp(xy, -1.0, 1.0)\n",
        "    return torch.movedim(xy, 0, -1).to(device)\n"
      ],
      "metadata": {
        "id": "GLIqqZrScBE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_pil_image(torch.movedim(create_uvmap_hexagonal_tiling(512), -1, 0)[[0, 0, 1]] * 0.5 + 0.5)"
      ],
      "metadata": {
        "id": "CUBNWJktWiPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFjuzGNKXuYB"
      },
      "outputs": [],
      "source": [
        "def create_uvmap_spiral(resolution,\n",
        "                        phase=0.0,\n",
        "                        scale=2.0,\n",
        "                        rotation=1,\n",
        "                        focus=(0.0, 0.5),\n",
        "                        aspect_ratio=1.0\n",
        "                        ):\n",
        "    x, y = torch.meshgrid(torch.linspace(-aspect_ratio,\n",
        "                                         aspect_ratio,\n",
        "                                         int(aspect_ratio*\n",
        "                                             resolution)),\n",
        "                          torch.linspace(-1.0, 1.0, resolution),\n",
        "                          indexing=\"xy\")\n",
        "\n",
        "    complex_focus = focus[0] + 1j * focus[1]\n",
        "    complex_transform = 1.0 / scale * cmath.exp(1j * rotation)\n",
        "    complex_offset = complex_focus * (1.0 - complex_transform)\n",
        "\n",
        "    x, y = x.cpu().data.numpy(), y.cpu().data.numpy()\n",
        "    z = x + 1j * y\n",
        "    uvmap = z.copy()\n",
        "\n",
        "    for i in range(-4, 10):\n",
        "        i = i + phase\n",
        "        center = ((1.0 - complex_transform ** i) /\n",
        "                    (1.0 - complex_transform) *\n",
        "                    complex_offset)\n",
        "        transform = complex_transform ** i\n",
        "        radius = abs(scale) ** (-i)\n",
        "        uvmap = np.where(abs(z - center) < radius,\n",
        "                         (z - center) / transform,\n",
        "                         uvmap)\n",
        "    output = torch.stack([torch.tensor(uvmap.real),\n",
        "                          torch.tensor(uvmap.imag)],\n",
        "                         dim=-1)\n",
        "    return output.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@interact\n",
        "def spiral(phase = 0.0):\n",
        "    uvmap_spiral = torch.movedim(create_uvmap_spiral(256, phase=phase), -1, 0)\n",
        "    display(to_pil_image(uvmap_spiral[[0, 0, 1]] * 0.5 + 0.5))"
      ],
      "metadata": {
        "id": "oXttCURRVZ4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation Function"
      ],
      "metadata": {
        "id": "W08vU4RxoEFX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX9WDvEPXZfk"
      },
      "outputs": [],
      "source": [
        "def generate(source_image,\n",
        "             uvmap_generator,\n",
        "             resolution,\n",
        "             uvmap_generator_latent=None,\n",
        "             mode=\"circular\"):\n",
        "    source_image = to_tensor(source_image)\n",
        "    source_image = source_image[None].to(device)\n",
        "\n",
        "    if uvmap_generator_latent is None:\n",
        "        uvmap_generator_latent = uvmap_generator\n",
        "\n",
        "    result = torch.zeros((1, 3, resolution, resolution)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        n_stages = int(math.log2(resolution))\n",
        "        for stage in range(n_stages):\n",
        "            stage_resolution = resolution // (2 ** stage)\n",
        "            stage_amplitude = 0.25 * (2 ** (n_stages - stage - 1))\n",
        "            noise_low_resolution = (0.5 + (torch.rand((1, 3,\n",
        "                                                    stage_resolution,\n",
        "                                                    stage_resolution)) - 0.5)\n",
        "                                    * stage_amplitude)\n",
        "            noise = interpolate(noise_low_resolution, (resolution, resolution))\n",
        "            result.data += noise.to(device)\n",
        "\n",
        "    for i in range(4, 0, -1):\n",
        "        with torch.no_grad():\n",
        "            source_image_resized = interpolate(\n",
        "                    source_image,\n",
        "                    (resolution // i, resolution // i),\n",
        "                    mode=\"area\"\n",
        "                )\n",
        "            result = interpolate(\n",
        "                    result.detach(),\n",
        "                    (resolution // i, resolution // i)\n",
        "                )\n",
        "            result = result.detach().requires_grad_(True)\n",
        "\n",
        "\n",
        "        uvmap = uvmap_generator(resolution // i)\n",
        "        run_optimization(result, source_image_resized, uvmap, mode=mode)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            uvmap_latent = uvmap_generator_latent(resolution // i)\n",
        "            result.data = grid_sample(\n",
        "                result,\n",
        "                uvmap_latent[None],\n",
        "                \"nearest\",\n",
        "                \"border\",\n",
        "                True)\n",
        "        display_result = result # grid_sample(result, uvmap[None], \"nearest\", \"border\", True)\n",
        "        display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "        display(to_pil_image(display_result[0]))\n",
        "    return to_pil_image(result[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvyWHGJ8YHEv"
      },
      "source": [
        "# Choose your algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## No Tiling"
      ],
      "metadata": {
        "id": "Z4KZ2HO9NfMi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvIeUW0JtgTB"
      },
      "outputs": [],
      "source": [
        "# source_image = PIL.Image.open(\"ArrowsTheorem.png\").convert(\"RGB\")\n",
        "uvmap_generator = lambda x: create_uvmap_identity(x)\n",
        "\n",
        "output = generate(source_image, uvmap_generator, resolution=256, mode=\"reflect\")\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKN3rdeUthcn"
      },
      "outputs": [],
      "source": [
        "uvmap = create_uvmap_identity(256)\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "display(to_pil_image(display_result[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Square Tiling"
      ],
      "metadata": {
        "id": "aSUUiFzIcZzX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvGRxCS-cZz1"
      },
      "outputs": [],
      "source": [
        "\n",
        "uvmap_generator = lambda x: create_uvmap_identity(x)\n",
        "\n",
        "output = generate(source_image, uvmap_generator, resolution=256)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWeKUK-AcZz2"
      },
      "outputs": [],
      "source": [
        "uvmap = create_uvmap_square_tiling(1024, canvas_multiplier=2)\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "display(to_pil_image(display_result[0]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resolution = 256\n",
        "\n",
        "canvas_multiplier = 2\n",
        "\n",
        "uvmap = create_uvmap_square_tiling(resolution,\n",
        "                                   canvas_multiplier=canvas_multiplier)\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "\n",
        "uvmap_blurred = torch.moveaxis(\n",
        "    avg_pool2d(torch.moveaxis(uvmap, -1, 0)[None], 5, 1, 2)[0],\n",
        "    0, -1)\n",
        "\n",
        "grid_outlines = (torch.max((uvmap_blurred - uvmap).abs(), dim=-1)[0] > 0.25)\n",
        "\n",
        "y, x = torch.meshgrid(\n",
        "    torch.linspace(-canvas_multiplier, canvas_multiplier, display_result.shape[2]),\n",
        "    torch.linspace(-canvas_multiplier, canvas_multiplier, display_result.shape[3]),\n",
        ")\n",
        "\n",
        "grid_outlines = torch.min(grid_outlines, (x * x + y * y).to(device) < 2).float()\n",
        "\n",
        "display_result = ((1.0 - display_result) * grid_outlines * 0.7 +\n",
        "                  (1.0 - grid_outlines) * display_result)\n",
        "\n",
        "pil_canvas = to_pil_image(display_result[0])\n",
        "display(pil_canvas)"
      ],
      "metadata": {
        "id": "d300QzhNjB05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hexagonal Tiling"
      ],
      "metadata": {
        "id": "f9S1BELBNZO7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOqzHe_MwD4g"
      },
      "outputs": [],
      "source": [
        "uvmap_generator_latent = lambda x: create_uvmap_hexagonal_tiling(\n",
        "    x, crop_rectangle=(-1, -1, 1, 1)\n",
        ")\n",
        "uvmap_generator = lambda x: create_uvmap_hexagonal_tiling(x)\n",
        "\n",
        "output = generate(source_image,\n",
        "                  uvmap_generator,\n",
        "                  uvmap_generator_latent=uvmap_generator_latent,\n",
        "                  resolution=300)\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uvmap = create_uvmap_hexagonal_tiling(256,\n",
        "                                      (-3, -3, 3, 3))\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "display(to_pil_image(display_result[0]))"
      ],
      "metadata": {
        "id": "jugy4yXwh2aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resolution = 256\n",
        "\n",
        "x_min = -2\n",
        "y_min = -2\n",
        "x_max = 2\n",
        "y_max = 2\n",
        "\n",
        "uvmap = create_uvmap_hexagonal_tiling(resolution,\n",
        "                                      (x_min, y_min, x_max, y_max))\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "\n",
        "uvmap_blurred = torch.moveaxis(\n",
        "    avg_pool2d(torch.moveaxis(uvmap, -1, 0)[None], 5, 1, 2)[0],\n",
        "    0, -1)\n",
        "\n",
        "grid_outlines = (torch.max((uvmap_blurred - uvmap).abs(), dim=-1)[0] > 0.25)\n",
        "\n",
        "y, x = torch.meshgrid(\n",
        "    torch.linspace(y_min, y_max, display_result.shape[2]),\n",
        "    torch.linspace(x_min, x_max, display_result.shape[3]),\n",
        ")\n",
        "\n",
        "grid_outlines = torch.min(grid_outlines, (x * x + y * y).to(device) < 1).float()\n",
        "\n",
        "display_result = ((1.0 - display_result) * grid_outlines * 0.7 +\n",
        "                  (1.0 - grid_outlines) * display_result)\n",
        "\n",
        "pil_canvas = to_pil_image(display_result[0])\n",
        "display(pil_canvas)"
      ],
      "metadata": {
        "id": "GcFYj1INqe5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zoom in loop"
      ],
      "metadata": {
        "id": "kJUa3P13NlTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation"
      ],
      "metadata": {
        "id": "hbF5wVw89IJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "uvmap_generator = lambda x: create_uvmap_spiral(x)\n",
        "\n",
        "output = generate(source_image, uvmap_generator, resolution=500)\n",
        "output"
      ],
      "metadata": {
        "id": "WfRW9ELzmYcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "### Demonstration"
      ],
      "metadata": {
        "id": "OFNM6x4L9LXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uvmap = uvmap_generator(256)\n",
        "\n",
        "display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                             uvmap[None],\n",
        "                             \"nearest\",\n",
        "                             \"border\",\n",
        "                             True)\n",
        "display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "display(to_pil_image(display_result[0]))"
      ],
      "metadata": {
        "id": "ijcW6NRzN9HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Export"
      ],
      "metadata": {
        "id": "hSgVRrXn9P6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "\n",
        "for phase in tqdm.tqdm(np.linspace(1.0, 0.0, 120)):\n",
        "    uvmap = create_uvmap_spiral(500, phase=phase, aspect_ratio=2.0)\n",
        "\n",
        "    display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                                uvmap[None],\n",
        "                                \"nearest\",\n",
        "                                \"border\",\n",
        "                                True)\n",
        "    display_result = avg_pool2d(display_result, (2, 2), (2, 2))\n",
        "    display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "    frames.append(to_pil_image(display_result[0]))\n",
        "\n",
        "\n",
        "first_frame = frames[0]\n",
        "first_frame.save(\"spiral.gif\",\n",
        "                 save_all=True,\n",
        "                 append_images=frames[1:],\n",
        "                 duration=25,\n",
        "                 loop=0)"
      ],
      "metadata": {
        "id": "_6L6ls7G8EqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_raw = []\n",
        "for phase in tqdm.tqdm(np.linspace(1.0, 0.0, 60)):\n",
        "    uvmap = create_uvmap_spiral(500, phase=phase, aspect_ratio=2.0)\n",
        "\n",
        "    display_result = grid_sample(to_tensor(output)[None].to(device),\n",
        "                                uvmap[None],\n",
        "                                \"nearest\",\n",
        "                                \"border\",\n",
        "                                True)\n",
        "    display_result = avg_pool2d(display_result, (2, 2), (2, 2))\n",
        "    display_result = torch.clamp(display_result, 0.0, 1.0)\n",
        "    frames_raw.append(display_result[0])\n",
        "\n",
        "\n",
        "frames = [to_pil_image(a * 0.2 + b * 0.8) for a, b in\n",
        "          zip(tqdm.tqdm(frames_raw[::2]), frames_raw[1::2])]\n",
        "\n",
        "first_frame = frames[0]\n",
        "first_frame.save(\"spiral.gif\",\n",
        "                 save_all=True,\n",
        "                 append_images=frames[1:],\n",
        "                 duration=40,\n",
        "                 loop=0)"
      ],
      "metadata": {
        "id": "jgblETdJ-KJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_frame"
      ],
      "metadata": {
        "id": "aQLn5Hz4WJwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --execute --to html \"/content/123.ipynb\"\n"
      ],
      "metadata": {
        "id": "EYKGcX1f6kqR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}